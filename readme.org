
Parse all of Pubchem and get a set of fields. Convert into parquet and compare to JUMP
#+begin_src shell
  # Pull pubchem data from ftp server
  mkdir -p 
  wget -r ftp://ftp.ncbi.nlm.nih.gov/pubchem/Compound/CURRENT-Full/XML

  cd ftp.ncbi.nlm.nih.gov/pubchem/Compound/CURRENT-Full/XML

  # Extract zip
  parallel pzip -d | *.gz

  # Run this awk script to extract fields of interest
  find . -name "*xml" | parallel --verbose --results out '../../../../mawk -F \'[<>]\' -v OFS="," -f fetch.awk' &| less

  # Merge based on InChiKeys, convert the (hex) fingerprint to bitstrings and remove prefix (4 bytes) and suffix (7 bits)  
  # based on the specification

  duckdb -c "INSTALL httpfs; LOAD httpfs; COPY (SELECT * EXCLUDE(Metadata_InChIKey),fingerprint AS fingerprint FROM (SELECT Metadata_JCP2022,Metadata_InChIKey FROM 'https://github.com/jump-cellpainting/datasets/raw/refs/heads/main/metadata/compound.csv.gz') A LEFT JOIN (SELECT *, FROM read_csv('out/1/*/stdout') ) B ON A.Metadata_InChIKey = B.InChIKey) TO 'table.parquet' (FORMAT parquet, COMPRESSION zstd)"
  
  mv table.parquet ../../../../data
  #+end_src
  
** Dependencies
I use Nix to manage dependencies to pull the relevant data and delegate the interface to a Marimo WASM notebook.

- Download, parse and format puchem data and compare it to JUMP: See flake.nix
- Interface: marimo, but can be run on the browser.
  
** Additional notes:
- Marimo is not a dependency despite the notebook at the root because ideally we want an isolated WASM website.
- There is an issue with the httpfs extension in WASM notebooks, so I am shipping the script with the data for now ([[https://github.com/marimo-team/marimo/issues/4308][issue]]).
